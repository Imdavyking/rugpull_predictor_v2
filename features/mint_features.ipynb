{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    amount       amount0     amount1    amountUSD  \\\n",
      "0    613460599434217667567  1.938998e+03    0.426067  3319.199673   \n",
      "1    891849916738551272778  0.000000e+00    2.000000  6313.274661   \n",
      "2  17701992740182515804492  1.636746e+04    1.811366  2780.160697   \n",
      "3     60361793806163010168  1.445108e+05    0.000073     0.162941   \n",
      "4  48928544071541478942235  2.394002e+07  100.000000     0.000000   \n",
      "\n",
      "                                                  id  logIndex  \\\n",
      "0  0x0000118dcfb5178f1776acb8d6c3f1229eb84475c5c5...       176   \n",
      "1  0x00001a3315046ff0782b5becdad6a43855d1e5a0e683...        97   \n",
      "2  0x00001c5d54ad8669ec30ac71a4e8d7eae7096bb4fae5...       641   \n",
      "3  0x0000205d7b543532a515537a0f70e6eb63103ebd80ec...       471   \n",
      "4  0x000030188de410a6ad662a97e1b0ba2b1e9868863b80...       214   \n",
      "\n",
      "                                       origin  \\\n",
      "0  0xadc8aaddf5dcf81366fcc0212c154dfbfde1ed13   \n",
      "1  0x57db5d6aa783cf29af41330569d24957140fd3eb   \n",
      "2  0x99dd497521cdd8371daca3314c89864dc21bf818   \n",
      "3  0xad5d9efb7961d88ee91f7119e92f47081a7fe64a   \n",
      "4  0xbd4713eab86029180770da858df526c7f2a51d2b   \n",
      "\n",
      "                                        owner  \\\n",
      "0  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "1  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "2  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "3  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "4  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "\n",
      "                                       sender  tickLower  tickUpper  \\\n",
      "0  0xc36442b4a4522e871399cd717abdd847ab11fe88     -81610     -79660   \n",
      "1  0xc36442b4a4522e871399cd717abdd847ab11fe88     -38160     -37860   \n",
      "2  0xc36442b4a4522e871399cd717abdd847ab11fe88     -87000     -86600   \n",
      "3  0xc36442b4a4522e871399cd717abdd847ab11fe88    -214500    -212280   \n",
      "4  0xc36442b4a4522e871399cd717abdd847ab11fe88    -887200     887200   \n",
      "\n",
      "    timestamp                                     pool.id  \n",
      "0  1629611736  0x60594a405d53811d3bc4766596efd80fd545a270  \n",
      "1  1628642635  0x3019d4e366576a88d28b623afaf3ecb9ec9d9580  \n",
      "2  1697149715  0x32121e0d11ecc79035045bc7466ede30816c5674  \n",
      "3  1704335999  0x11950d141ecb863f01007add7d1a342041227b58  \n",
      "4  1670285783  0x150abc3985c50dc2ae81db11f7c41d775c7fe6b9  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mints_df = pd.read_csv('../data/mints.csv', low_memory=False)\n",
    "rugpull_labels_df = pd.read_csv('../data/rugpulls_with_token_info.csv', low_memory=False)\n",
    "\n",
    "# Ensure that 'id' is the correct identifier for pools\n",
    "print(mints_df.head())\n",
    "\n",
    "# Convert 'date' to a datetime object\n",
    "mints_df['timestamp'] = pd.to_datetime(mints_df['timestamp'], unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pool 0: Pool ID 0x000c0d31f6b7cecde4645eef0c4ec6a492659d62\n",
      "Number of pools skipped: 0\n",
      "Processing pool 200: Pool ID 0x0a1665e3f54eeb364bec6954e4497dd802840a01\n",
      "Number of pools skipped: 0\n",
      "Processing pool 400: Pool ID 0x152ac8b0358a215fe1f6dd75c8804e4f6ca046eb\n",
      "Number of pools skipped: 0\n",
      "Processing pool 600: Pool ID 0x1f138debc0721b364a967b09402b45069cba7b35\n",
      "Number of pools skipped: 0\n",
      "Processing pool 800: Pool ID 0x291dae7ebf6193910bf69cb14f121c07cfea4de0\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1000: Pool ID 0x3429e990337542434f6bfac5a4d9f14ed285ac7a\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1200: Pool ID 0x3e441eb04d28e1f8cac30f6e32d736a96d8a13b1\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1400: Pool ID 0x46ca72148708fbc450e046fffd264a7821f70ba3\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1600: Pool ID 0x51195c58837babb4ae172c3ac4e29bdc50db4058\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1800: Pool ID 0x5aac14ca709846c709f746350ca1f739462027a3\n",
      "Number of pools skipped: 0\n",
      "Processing pool 2000: Pool ID 0x632881d9f6231bee100cf7d060cc27d86b2a5cdb\n",
      "Number of pools skipped: 0\n",
      "Processing pool 2200: Pool ID 0x6cff6cce76995af3a962e64b956be8b4020889eb\n",
      "Number of pools skipped: 0\n",
      "Processing pool 2400: Pool ID 0x77532d31f043aa870f745615854bbc987aabc14c\n",
      "Number of pools skipped: 0\n",
      "Processing pool 2600: Pool ID 0x811c9e30dad67f0e02b89cf66d42f75c41fc68aa\n",
      "Number of pools skipped: 0\n",
      "Processing pool 2800: Pool ID 0x89cc4216e0a61152fb631c9b3bdc825d5373e43f\n",
      "Number of pools skipped: 0\n",
      "Skipping pool 0x8f4828e4900bd0c7ad91879bfd3a90ced445d1fa because there is no data before the rugpull date\n",
      "Processing pool 3000: Pool ID 0x943c66d78875ddeb3aede2ac081625d0a947bbad\n",
      "Number of pools skipped: 0\n",
      "Processing pool 3200: Pool ID 0x9e5bfb074aa3a90daf84484f9e099ad39d64d578\n",
      "Number of pools skipped: 0\n",
      "Processing pool 3400: Pool ID 0xa81fb934e257df74dfd113e1dafbc98a5fe10469\n",
      "Number of pools skipped: 0\n",
      "Processing pool 3600: Pool ID 0xb11d15da84a206670beba4e8172c69e653516e80\n",
      "Number of pools skipped: 0\n",
      "Processing pool 3800: Pool ID 0xbadec352e0dd27f6977e14c8cd770f67d9749aae\n",
      "Number of pools skipped: 0\n",
      "Processing pool 4000: Pool ID 0xc4090b37eeff584fc48c58e9d2303acca82247dc\n",
      "Number of pools skipped: 0\n",
      "Processing pool 4200: Pool ID 0xce3dd41cfe1d14e66df18fa66ff5bb1dfd98b880\n",
      "Number of pools skipped: 0\n",
      "Processing pool 4400: Pool ID 0xd86c5cfb2682e4c097177b41bd8127fb56af455b\n",
      "Number of pools skipped: 0\n",
      "Processing pool 4600: Pool ID 0xe2373abf8c81ac76fa7846cda0de14d1255a3ac7\n",
      "Number of pools skipped: 0\n",
      "Processing pool 4800: Pool ID 0xea687867b52edd80365e4d266a60b6a169225051\n",
      "Number of pools skipped: 0\n",
      "Processing pool 5000: Pool ID 0xf3b2204b3b326131829b34f94eda81d65c878e84\n",
      "Number of pools skipped: 0\n",
      "Processing pool 5200: Pool ID 0xfc85f40cd8ae99100100d535b3675ce67c49f33d\n",
      "Number of pools skipped: 0\n",
      "                                      pool_id  top_owner_1_distribution  \\\n",
      "0  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62                  0.300585   \n",
      "1  0x000ea4a83acefdd62b1b43e9ccc281f442651520                  0.928069   \n",
      "2  0x000fedac8a4c7f2c291c5bca0fd244e17e27c763                  1.000000   \n",
      "3  0x0025ade782cc2b2415d1e841a8d52ff5dce33dfe                  1.000000   \n",
      "4  0x005e3dc62b7a269bef2a7d06e06cc0c991375c6f                  1.000000   \n",
      "\n",
      "   top_owner_2_distribution  top_owner_3_distribution  \\\n",
      "0                  0.134287                  0.107748   \n",
      "1                  0.054059                  0.007370   \n",
      "2                  0.000000                  0.000000   \n",
      "3                  0.000000                  0.000000   \n",
      "4                  0.000000                  0.000000   \n",
      "\n",
      "   top_owner_4_distribution  top_owner_5_distribution  \\\n",
      "0                  0.083342                  0.066281   \n",
      "1                  0.004400                  0.002094   \n",
      "2                  0.000000                  0.000000   \n",
      "3                  0.000000                  0.000000   \n",
      "4                  0.000000                  0.000000   \n",
      "\n",
      "   top_owner_6_distribution  top_owner_7_distribution  \\\n",
      "0                  0.057437                  0.039783   \n",
      "1                  0.001730                  0.000956   \n",
      "2                  0.000000                  0.000000   \n",
      "3                  0.000000                  0.000000   \n",
      "4                  0.000000                  0.000000   \n",
      "\n",
      "   top_owner_8_distribution  top_owner_9_distribution  \\\n",
      "0                  0.034897                  0.032924   \n",
      "1                  0.000511                  0.000323   \n",
      "2                  0.000000                  0.000000   \n",
      "3                  0.000000                  0.000000   \n",
      "4                  0.000000                  0.000000   \n",
      "\n",
      "   top_owner_10_distribution  \n",
      "0                   0.029968  \n",
      "1                   0.000248  \n",
      "2                   0.000000  \n",
      "3                   0.000000  \n",
      "4                   0.000000  \n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the feature rows\n",
    "feature_rows = []\n",
    "# Initialize an empty DataFrame for mint features\n",
    "mint_features = pd.DataFrame()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "count = 0\n",
    "# Initialize a list to store the feature rows\n",
    "feature_rows = []\n",
    "# Initialize a DataFrame to store the features\n",
    "pool_features = pd.DataFrame()\n",
    "\n",
    "for index, pool_id in enumerate(rugpull_labels_df['pool_id']):\n",
    "    if index % 200 == 0:\n",
    "        print(f\"Processing pool {index}: Pool ID {pool_id}\")\n",
    "        print(f\"Number of pools skipped: {count}\")\n",
    "        # if index > 0: break\n",
    "\n",
    "    rugpull_date = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['date'].iloc[0] # Get the rugpull date for this pool\n",
    "\n",
    "    token0_symbol = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['token0.symbol'].iloc[0]\n",
    "    token1_symbol = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['token1.symbol'].iloc[0]\n",
    "\n",
    "    # print(rugpull_date)\n",
    "    mint_data = mints_df[mints_df['pool.id'] == pool_id]\n",
    "\n",
    "    # if (len(mint_data) < 3):\n",
    "    #     # print(f\"Skipping pool {pool_id} because there is no data\")\n",
    "    #     count += 1\n",
    "    #     continue\n",
    "\n",
    "    # If rugpull_date is NaT, use all available data; else filter data before rugpull\n",
    "    # pre_rugpull_data = mint_data if pd.isna(rugpull_date) else mint_data[mint_data['timestamp'] < rugpull_date]\n",
    "    pre_rugpull_data = mint_data.copy() if pd.isna(rugpull_date) else mint_data[mint_data['timestamp'] < rugpull_date].copy()\n",
    "    \n",
    "    if pre_rugpull_data.empty:\n",
    "        print(f\"Skipping pool {pool_id} because there is no data before the rugpull date\")\n",
    "        continue\n",
    "\n",
    "    # Convert 'amount' to Decimal to handle very large numbers\n",
    "    pre_rugpull_data['amount'] = pre_rugpull_data['amount'].apply(lambda x: Decimal(x))\n",
    "\n",
    "    # Calculate distribution metrics\n",
    "    grouped_owners = pd.to_numeric(pre_rugpull_data.groupby('origin')['amount'].sum())\n",
    "    top_owners = grouped_owners.nlargest(10)\n",
    "    total_minted_amount = grouped_owners.sum()\n",
    "\n",
    "    # total_minted_amount = pre_rugpull_data['amount'].sum()\n",
    "    # distribution_top_10 = top_owners_amount / total_minted_amount if total_minted_amount != 0 else 0\n",
    "    \n",
    "    pre_rugpull_data = pre_rugpull_data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Identify if token0 or token1 is WETH and rename columns\n",
    "    if token0_symbol == 'WETH':\n",
    "        weth_token = 'amount0'\n",
    "        otherToken = 'amount1'\n",
    "    elif token1_symbol == 'WETH':\n",
    "        weth_token = 'amount1'\n",
    "        otherToken = 'amount0'\n",
    "    else:\n",
    "        print(f\"Skipping pool {pool_id} because neither token is WETH\")\n",
    "        continue\n",
    "\n",
    "    # Rename columns\n",
    "    pre_rugpull_data.columns = [col.lower().replace(weth_token, 'wethToken').replace(otherToken, 'otherToken') for col in pre_rugpull_data.columns]\n",
    "\n",
    "    # # Debugging: Print new column names\n",
    "    # print(\"New Column Names:\", pre_rugpull_data.columns)\n",
    "    \n",
    "    # Calculate mean and variance for relevant columns\n",
    "    # means = pre_rugpull_data.mean().fillna(0)\n",
    "    # variances = pre_rugpull_data.var().fillna(0)  # Replacing NaN with 0\n",
    "\n",
    "    feature_row = {}\n",
    "\n",
    "    feature_row = {'pool_id': pool_id}\n",
    "    # for mean in means.index:\n",
    "    #     feature_row[f'mean_{mean}'] = means[mean]\n",
    "    # for variance in variances.index:\n",
    "    #     feature_row[f'variance_{variance}'] = variances[variance]\n",
    "    # Fill in the distributions for the top owners\n",
    "    for i in range(10):\n",
    "        if i < len(top_owners):\n",
    "            owner = top_owners.index[i]\n",
    "            amount = top_owners.iloc[i]\n",
    "            distribution = float(amount / total_minted_amount) if total_minted_amount != 0 else 0\n",
    "        else:\n",
    "            # If there are less than 10 owners, fill the rest with 0\n",
    "            owner = None\n",
    "            distribution = 0\n",
    "\n",
    "        feature_row[f'top_owner_{i+1}_distribution'] = distribution\n",
    "\n",
    "    feature_rows.append(feature_row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "pool_features = pd.DataFrame(feature_rows)\n",
    "\n",
    "print(pool_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_pool_data4.csv\n"
     ]
    }
   ],
   "source": [
    "pool_data_with_labels = pd.read_csv('../data/merged_pool_data3.csv', low_memory=False)\n",
    "\n",
    "# Merge the DataFrames on the 'pool_id' column\n",
    "merged_data = pool_data_with_labels.merge(pool_features, on='pool_id', how='left')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file, if needed\n",
    "merged_data.to_csv('../data/merged_pool_data4.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved to merged_pool_data4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
