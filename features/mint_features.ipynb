{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    amount       amount0     amount1    amountUSD  \\\n",
      "0    613460599434217667567  1.938998e+03    0.426067  3319.199673   \n",
      "1    891849916738551272778  0.000000e+00    2.000000  6313.274661   \n",
      "2  17701992740182515804492  1.636746e+04    1.811366  2780.160697   \n",
      "3     60361793806163010168  1.445108e+05    0.000073     0.162941   \n",
      "4  48928544071541478942235  2.394002e+07  100.000000     0.000000   \n",
      "\n",
      "                                                  id  logIndex  \\\n",
      "0  0x0000118dcfb5178f1776acb8d6c3f1229eb84475c5c5...       176   \n",
      "1  0x00001a3315046ff0782b5becdad6a43855d1e5a0e683...        97   \n",
      "2  0x00001c5d54ad8669ec30ac71a4e8d7eae7096bb4fae5...       641   \n",
      "3  0x0000205d7b543532a515537a0f70e6eb63103ebd80ec...       471   \n",
      "4  0x000030188de410a6ad662a97e1b0ba2b1e9868863b80...       214   \n",
      "\n",
      "                                       origin  \\\n",
      "0  0xadc8aaddf5dcf81366fcc0212c154dfbfde1ed13   \n",
      "1  0x57db5d6aa783cf29af41330569d24957140fd3eb   \n",
      "2  0x99dd497521cdd8371daca3314c89864dc21bf818   \n",
      "3  0xad5d9efb7961d88ee91f7119e92f47081a7fe64a   \n",
      "4  0xbd4713eab86029180770da858df526c7f2a51d2b   \n",
      "\n",
      "                                        owner  \\\n",
      "0  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "1  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "2  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "3  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "4  0xc36442b4a4522e871399cd717abdd847ab11fe88   \n",
      "\n",
      "                                       sender  tickLower  tickUpper  \\\n",
      "0  0xc36442b4a4522e871399cd717abdd847ab11fe88     -81610     -79660   \n",
      "1  0xc36442b4a4522e871399cd717abdd847ab11fe88     -38160     -37860   \n",
      "2  0xc36442b4a4522e871399cd717abdd847ab11fe88     -87000     -86600   \n",
      "3  0xc36442b4a4522e871399cd717abdd847ab11fe88    -214500    -212280   \n",
      "4  0xc36442b4a4522e871399cd717abdd847ab11fe88    -887200     887200   \n",
      "\n",
      "    timestamp                                     pool.id  \n",
      "0  1629611736  0x60594a405d53811d3bc4766596efd80fd545a270  \n",
      "1  1628642635  0x3019d4e366576a88d28b623afaf3ecb9ec9d9580  \n",
      "2  1697149715  0x32121e0d11ecc79035045bc7466ede30816c5674  \n",
      "3  1704335999  0x11950d141ecb863f01007add7d1a342041227b58  \n",
      "4  1670285783  0x150abc3985c50dc2ae81db11f7c41d775c7fe6b9  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mints_df = pd.read_csv('mints.csv', low_memory=False)\n",
    "rugpull_labels_df = pd.read_csv('rugpulls_with_token_info.csv', low_memory=False)\n",
    "\n",
    "# Ensure that 'id' is the correct identifier for pools\n",
    "print(mints_df.head())\n",
    "\n",
    "# Convert 'date' to a datetime object\n",
    "mints_df['timestamp'] = pd.to_datetime(mints_df['timestamp'], unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pool 0: Pool ID 0x000c0d31f6b7cecde4645eef0c4ec6a492659d62\n",
      "Number of pools skipped: 0\n",
      "Processing pool 200: Pool ID 0x0a1665e3f54eeb364bec6954e4497dd802840a01\n",
      "Number of pools skipped: 0\n",
      "Processing pool 400: Pool ID 0x152ac8b0358a215fe1f6dd75c8804e4f6ca046eb\n",
      "Number of pools skipped: 0\n",
      "Processing pool 600: Pool ID 0x1f138debc0721b364a967b09402b45069cba7b35\n",
      "Number of pools skipped: 0\n",
      "Processing pool 800: Pool ID 0x291dae7ebf6193910bf69cb14f121c07cfea4de0\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1000: Pool ID 0x3429e990337542434f6bfac5a4d9f14ed285ac7a\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1200: Pool ID 0x3e441eb04d28e1f8cac30f6e32d736a96d8a13b1\n",
      "Number of pools skipped: 0\n",
      "Processing pool 1400: Pool ID 0x46ca72148708fbc450e046fffd264a7821f70ba3\n",
      "Number of pools skipped: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the feature rows\n",
    "feature_rows = []\n",
    "# Initialize an empty DataFrame for mint features\n",
    "mint_features = pd.DataFrame()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "count = 0\n",
    "# Initialize a list to store the feature rows\n",
    "feature_rows = []\n",
    "# Initialize a DataFrame to store the features\n",
    "pool_features = pd.DataFrame()\n",
    "\n",
    "for index, pool_id in enumerate(rugpull_labels_df['pool_id']):\n",
    "    if index % 200 == 0:\n",
    "        print(f\"Processing pool {index}: Pool ID {pool_id}\")\n",
    "        print(f\"Number of pools skipped: {count}\")\n",
    "        # if index > 0: break\n",
    "\n",
    "    rugpull_date = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['date'].iloc[0] # Get the rugpull date for this pool\n",
    "\n",
    "    token0_symbol = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['token0.symbol'].iloc[0]\n",
    "    token1_symbol = rugpull_labels_df[rugpull_labels_df['pool_id'] == pool_id]['token1.symbol'].iloc[0]\n",
    "\n",
    "    # print(rugpull_date)\n",
    "    mint_data = mints_df[mints_df['pool.id'] == pool_id]\n",
    "\n",
    "    # if (len(mint_data) < 3):\n",
    "    #     # print(f\"Skipping pool {pool_id} because there is no data\")\n",
    "    #     count += 1\n",
    "    #     continue\n",
    "\n",
    "    # If rugpull_date is NaT, use all available data; else filter data before rugpull\n",
    "    pre_rugpull_data = mint_data if pd.isna(rugpull_date) else mint_data[mint_data['timestamp'] < rugpull_date]\n",
    "    \n",
    "    if pre_rugpull_data.empty:\n",
    "        print(f\"Skipping pool {pool_id} because there is no data before the rugpull date\")\n",
    "        continue\n",
    "\n",
    "    # # Calculate the distribution of minted tokens for the top 10 addresses\n",
    "    # grouped_owners = pre_rugpull_data.groupby('origin')['amount'].sum()\n",
    "    # print(grouped_owners[0])\n",
    "    # top_owners_amount = grouped_owners.nlargest(10).sum()\n",
    "    # total_minted_amount = grouped_owners.sum()\n",
    "    # distribution_top_10 = top_owners_amount / total_minted_amount if total_minted_amount != 0 else 0\n",
    "\n",
    "    # total_minted_amount = pre_rugpull_data['amount'].sum()\n",
    "    # distribution_top_10 = top_owners_amount / total_minted_amount if total_minted_amount != 0 else 0\n",
    "    \n",
    "    pre_rugpull_data = pre_rugpull_data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Identify if token0 or token1 is WETH and rename columns\n",
    "    if token0_symbol == 'WETH':\n",
    "        weth_token = 'amount0'\n",
    "        otherToken = 'amount1'\n",
    "    elif token1_symbol == 'WETH':\n",
    "        weth_token = 'amount1'\n",
    "        otherToken = 'amount0'\n",
    "    else:\n",
    "        print(f\"Skipping pool {pool_id} because neither token is WETH\")\n",
    "        continue\n",
    "\n",
    "    # Rename columns\n",
    "    pre_rugpull_data.columns = [col.lower().replace(weth_token, 'wethToken').replace(otherToken, 'otherToken') for col in pre_rugpull_data.columns]\n",
    "\n",
    "    # # Debugging: Print new column names\n",
    "    # print(\"New Column Names:\", pre_rugpull_data.columns)\n",
    "    \n",
    "    # Calculate mean and variance for relevant columns\n",
    "    means = pre_rugpull_data.mean().fillna(0)\n",
    "    variances = pre_rugpull_data.var().fillna(0)  # Replacing NaN with 0\n",
    "\n",
    "    feature_row = {}\n",
    "\n",
    "    feature_row = {'pool_id': pool_id}\n",
    "    for mean in means.index:\n",
    "        feature_row[f'mean_{mean}'] = means[mean]\n",
    "    for variance in variances.index:\n",
    "        feature_row[f'variance_{variance}'] = variances[variance]\n",
    "        \n",
    "    feature_rows.append(feature_row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "pool_features = pd.DataFrame(feature_rows)\n",
    "\n",
    "print(pool_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_data_with_labels = pd.read_csv('pool_feature_data_with_labels.csv', low_memory=False)\n",
    "\n",
    "# Merge the DataFrames on the 'pool_id' column\n",
    "merged_data = pool_data_with_labels.merge(pool_features, on='pool_id', how='left')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file, if needed\n",
    "merged_data.to_csv('merged_pool_data.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved to merged_pool_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
