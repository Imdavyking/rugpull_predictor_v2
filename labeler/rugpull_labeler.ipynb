{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the pool day data\n",
    "pool_day_data_df = pd.read_csv('pool_day_data.csv', low_memory=False)  # Addressing DtypeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "# Assuming 'date' column is in Unix timestamp format (seconds since epoch)\n",
    "pool_day_data_df['date'] = pd.to_datetime(pool_day_data_df['date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19234\n"
     ]
    }
   ],
   "source": [
    "# Load the pool day data\n",
    "pools_data_df = pd.read_csv('pools.csv', low_memory=False)  # Addressing DtypeWarning\n",
    "\n",
    "print(len(pools_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13493\n"
     ]
    }
   ],
   "source": [
    "# Get pools that have WETH\n",
    "\n",
    "WETH = \"WETH\"  # Replace with actual WETH address\n",
    "filtered_pools = pools_data_df[((pools_data_df['token0.symbol'] == WETH) | (pools_data_df['token1.symbol'] == WETH))].copy()\n",
    "filtered_pools.sort_values(by=['id'], inplace=True)\n",
    "\n",
    "# Extract pool IDs\n",
    "weth_pool_ids = filtered_pools['id'].unique()\n",
    "\n",
    "print(len(weth_pool_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7641\n"
     ]
    }
   ],
   "source": [
    "# Get pools that had more than 5000 TVL at one point\n",
    "\n",
    "# Filter for days where TVL > $5000\n",
    "high_tvl_days = pool_day_data_df[pool_day_data_df['totalValueLockedUSD'] > 5000]\n",
    "\n",
    "# Get unique pool IDs from these rows\n",
    "high_tvl_pool_ids = high_tvl_days['pool.id'].unique()\n",
    "\n",
    "print(len(high_tvl_pool_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools with > $5000 TVL and involving WETH: 5272\n"
     ]
    }
   ],
   "source": [
    "# Find intersection of pool IDs\n",
    "intersection_pool_ids = set(high_tvl_pool_ids).intersection(set(weth_pool_ids))\n",
    "\n",
    "# Print the number of pools in the intersection\n",
    "print(f\"Number of pools with > $5000 TVL and involving WETH: {len(intersection_pool_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            close       date                  feeGrowthGlobal0X128  \\\n",
      "389  28792.894826 2023-03-16  154042374028593464275858183529511242   \n",
      "390  26778.491102 2023-03-17  172590147036242261772466326558608228   \n",
      "391  33242.284462 2023-03-18  178112612372930278976686998149752369   \n",
      "392  34927.776534 2023-03-19  200383769966655764133728242873124551   \n",
      "393  34031.117899 2023-03-20  209002689798712475513256353257342701   \n",
      "\n",
      "                         feeGrowthGlobal1X128       feesUSD          high  \\\n",
      "389  3500190821504896744612912852039898318463  10882.471209  3.402568e+38   \n",
      "390  3924761051846481640284323769347360814245   2029.219302  5.138232e-05   \n",
      "391  4160622340317159998835969006041881367836    764.707837  3.909948e-05   \n",
      "392  4918557819042234731605056519108076409604   1341.174786  4.044482e-05   \n",
      "393  5203913553972883546527313527848417477521    480.124937  3.873842e-05   \n",
      "\n",
      "                                                   id  \\\n",
      "389  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62-19432   \n",
      "390  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62-19433   \n",
      "391  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62-19434   \n",
      "392  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62-19435   \n",
      "393  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62-19436   \n",
      "\n",
      "                   liquidity       low      open  \\\n",
      "389  13193236052714872218563  0.000027  0.000035   \n",
      "390  14199968557534579137122  0.000035  0.000037   \n",
      "391  10890837923455932174033  0.000029  0.000030   \n",
      "392   5475296910046283839116  0.000022  0.000031   \n",
      "393   5457903580438193282815  0.000024  0.000029   \n",
      "\n",
      "                            sqrtPrice    tick  token0Price   token1Price  \\\n",
      "389  13443806383578467560896695711213  102683     0.000035  28792.894826   \n",
      "390  12965003392450669703895675234502  101958     0.000037  26778.491102   \n",
      "391  14445248405166704472961472430723  104120     0.000030  33242.284462   \n",
      "392  14806931035654388566489616746973  104615     0.000029  34927.776534   \n",
      "393  14615635094681573994911286693099  104355     0.000029  34031.117899   \n",
      "\n",
      "     totalValueLockedUSD  txCount  volumeToken0  volumeToken1     volumeUSD  \\\n",
      "389         79203.893953     1539    654.828225  1.623464e+07  1.088247e+06   \n",
      "390         45296.701374      339    118.221351  2.844290e+06  2.029219e+05   \n",
      "391         42639.276374      189     42.302882  1.302206e+06  7.647078e+04   \n",
      "392         34785.328404      198     74.628163  2.494758e+06  1.341175e+05   \n",
      "393         35613.407516       85     27.148809  9.247010e+05  4.801249e+04   \n",
      "\n",
      "                                        pool.id  \n",
      "389  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62  \n",
      "390  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62  \n",
      "391  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62  \n",
      "392  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62  \n",
      "393  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62  \n",
      "Number of entries in filtered pool day data: 681848\n"
     ]
    }
   ],
   "source": [
    "# Filter pool_day_data_df to include only the pools in the intersection\n",
    "filtered_pool_day_data = pool_day_data_df[pool_day_data_df['pool.id'].isin(intersection_pool_ids)]\n",
    "\n",
    "print(filtered_pool_day_data.head())  # Print first few rows to check\n",
    "print(f\"Number of entries in filtered pool day data: {len(filtered_pool_day_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rugpulls(dataframe):\n",
    "    rugpulls = []\n",
    "    for pool_id, group in dataframe.groupby('pool.id'):\n",
    "        group = group.sort_values(by='date')  # Ensure data is sorted by date\n",
    "        rugpull_detected = False\n",
    "        for i in range(1, len(group)):\n",
    "            previous_day_tvl = group.iloc[i-1]['totalValueLockedUSD']\n",
    "            current_day_tvl = group.iloc[i]['totalValueLockedUSD']\n",
    "            if current_day_tvl < 0.01 * previous_day_tvl and previous_day_tvl > 5000:  # Check for rugpull condition\n",
    "                rugpulls.append({\n",
    "                    'pool_id': pool_id,\n",
    "                    'date': group.iloc[i]['date'],\n",
    "                    'previous_day_tvl': previous_day_tvl,\n",
    "                    'current_day_tvl': current_day_tvl,\n",
    "                    'rugpull': True\n",
    "                })\n",
    "                rugpull_detected = True\n",
    "                break  # Only consider the first such drop\n",
    "\n",
    "        if not rugpull_detected:\n",
    "            # If no rugpull detected, add a record with rugpull as False\n",
    "            # You can choose the appropriate values for date, previous_day_tvl, and current_day_tvl\n",
    "            rugpulls.append({\n",
    "                'pool_id': pool_id,\n",
    "                'date': None,  # or the last date in group, or another placeholder\n",
    "                'previous_day_tvl': None,  # or another placeholder\n",
    "                'current_day_tvl': None,  # or another placeholder\n",
    "                'rugpull': False\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(rugpulls)\n",
    "\n",
    "\n",
    "rugpulls_df = detect_rugpulls(filtered_pool_day_data)\n",
    "rugpulls_df.to_csv('rugpulls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5272\n",
      "                                      pool_id       date  previous_day_tvl  \\\n",
      "0  0x000c0d31f6b7cecde4645eef0c4ec6a492659d62        NaT               NaN   \n",
      "1  0x000ea4a83acefdd62b1b43e9ccc281f442651520        NaT               NaN   \n",
      "2  0x000fedac8a4c7f2c291c5bca0fd244e17e27c763 2023-05-19      25271.091389   \n",
      "3  0x0025ade782cc2b2415d1e841a8d52ff5dce33dfe        NaT               NaN   \n",
      "4  0x005e3dc62b7a269bef2a7d06e06cc0c991375c6f 2022-05-12      12441.980803   \n",
      "\n",
      "   current_day_tvl  rugpull  \n",
      "0              NaN    False  \n",
      "1              NaN    False  \n",
      "2     7.200000e-15     True  \n",
      "3              NaN    False  \n",
      "4     3.073691e+01     True  \n",
      "1135\n"
     ]
    }
   ],
   "source": [
    "print(len(rugpulls_df))\n",
    "print(rugpulls_df.head())\n",
    "print(len(rugpulls_df[rugpulls_df['rugpull'] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only necessary columns from pools_df\n",
    "pools_subset_df = pools_data_df[['id', 'token0.id', 'token0.name', 'token0.symbol', 'token1.id', 'token1.name', 'token1.symbol']]\n",
    "\n",
    "# Merge rugpulls_df with the subset of pools data\n",
    "merged_df = rugpulls_df.merge(pools_subset_df, left_on='pool_id', right_on='id', how='left')\n",
    "\n",
    "# Drop the extra 'id' column from the merge\n",
    "merged_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "merged_df.to_csv('rugpulls_with_token_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "WETH_ID = \"0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\"\n",
    "\n",
    "# Load the rugpulls data with token info\n",
    "rugpulls_df = pd.read_csv('rugpulls_with_token_info.csv')\n",
    "\n",
    "# Get unique token IDs from both token0 and token1\n",
    "token_ids = set(rugpulls_df['token0.id']).union(set(rugpulls_df['token1.id']))\n",
    "\n",
    "# Remove WETH token ID from the set\n",
    "token_ids.discard(WETH_ID)  # Replace \"WETH\" with actual WETH token ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_token_data(token_id, api_key='EK-fewp2-ycMSQm7-3Qj3b'):\n",
    "    url = f'https://api.ethplorer.io/getTokenInfo/{token_id}?apiKey={api_key}'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for token {token_id}, status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for token {token_id}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4605\n"
     ]
    }
   ],
   "source": [
    "def fetch_token_data_in_batches(token_ids, batch_size=500, api_key='EK-fewp2-ycMSQm7-3Qj3b'):\n",
    "    batched_token_data = []\n",
    "\n",
    "    total_batches = len(token_ids) // batch_size + (1 if len(token_ids) % batch_size else 0)\n",
    "    for i in range(total_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = batch_start + batch_size\n",
    "        current_batch = token_ids[batch_start:batch_end]\n",
    "        \n",
    "        for token_id in current_batch:\n",
    "            data = get_token_data(token_id, api_key)\n",
    "            batched_token_data.append(data)\n",
    "        \n",
    "        print(f\"Completed batch {i+1} of {total_batches}\")\n",
    "\n",
    "    return batched_token_data\n",
    "\n",
    "# Convert the set to a list\n",
    "token_ids_list = list(token_ids)\n",
    "print(len(token_ids_list))\n",
    "# token_data = fetch_token_data_in_batches(token_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4605\n",
      "None 1582\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(len(token_data))\n",
    "# Check the first few elements of token_data\n",
    "token_data_dicts = []\n",
    "for i, item in enumerate(token_data):\n",
    "    if (type(item) != dict):\n",
    "        print(item, i)\n",
    "    else:\n",
    "        token_data_dicts.append(item)\n",
    "token_df = pd.DataFrame(token_data_dicts)\n",
    "token_df.to_csv('token_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
